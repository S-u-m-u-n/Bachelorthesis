---------------------------------------------------------------------------
- Find mistake in code. Why is the solution wrong if I'm using more than 32 threads per threadblock???
>>> No clue why solution is wrong. Non-deterministic in some cases => race-condition?



---------------------------------------------------------------------------
- Check assembly and compare vectorization vs without vectorization:
        cuobjdump -sass .dacecache/gemm/build/libgemm.so > assembly_non_vectorized.txt
        cuobjdump -sass .dacecache/gemm/build/libgemm.so > assembly_vectorized.txt
>>> Done, apparently no difference in Assembly... why not??



---------------------------------------------------------------------------
- Add cuTLASS performance for benchmarking. Check out https://developer.nvidia.com/blog/cutlass-linear-algebra-cuda/
>>> Done.
>>> Column-Major (nn) vs. (tt) Row-Major?
>>> Using --profiling-iterations=9 results in 10 iterations... why?
>>> Warmup iterations? --warmup-iterations=0



---------------------------------------------------------------------------
- Implement Thread Block Swizzling
>>> Done.
>>> Still need to check cases where the swizzled grid has a different number of blocks.


---------------------------------------------------------------------------
- Check in Neville's thesis how close he gets to cuBLAS



---------------------------------------------------------------------------
- Add testcases from Neville and test performance



---------------------------------------------------------------------------
- Implement Split K